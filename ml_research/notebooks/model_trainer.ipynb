{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10733787,"sourceType":"datasetVersion","datasetId":6655198},{"sourceId":10760367,"sourceType":"datasetVersion","datasetId":6674646},{"sourceId":10775574,"sourceType":"datasetVersion","datasetId":6685522},{"sourceId":10783107,"sourceType":"datasetVersion","datasetId":6691246},{"sourceId":259519,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":221858,"modelId":243627},{"sourceId":259526,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":221865,"modelId":243634}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    AdamW,\n    get_linear_schedule_with_warmup\n)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    confusion_matrix,\n    classification_report\n)\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:18:45.127735Z","iopub.execute_input":"2025-02-18T20:18:45.128095Z","iopub.status.idle":"2025-02-18T20:18:53.488081Z","shell.execute_reply.started":"2025-02-18T20:18:45.128071Z","shell.execute_reply":"2025-02-18T20:18:53.487368Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"RANDOM_SEED = 42\nBATCH_SIZE = 16\nMAX_LENGTH = 2000\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nMODEL_NAME = \"sergeyzh/rubert-tiny-turbo\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:18:53.489285Z","iopub.execute_input":"2025-02-18T20:18:53.489913Z","iopub.status.idle":"2025-02-18T20:18:53.542571Z","shell.execute_reply.started":"2025-02-18T20:18:53.489877Z","shell.execute_reply":"2025-02-18T20:18:53.541563Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Data Import","metadata":{}},{"cell_type":"code","source":"## General Data for first step of transfer learning\ndata_general = pd.read_csv(\"/kaggle/input/nexign/datasets.csv\")\ndata_general = data_general.drop(data_general.columns[0], axis=1)\ndata_general[\"len\"] = data_general[\"text\"].apply(len)\ndata_general = data_general.loc[data_general[\"len\"]<=MAX_LENGTH].copy()\n\ntrain_general, temp_general = train_test_split(\n    data_general, test_size=0.3, random_state=RANDOM_SEED\n)\n\ntest_general, val_general = train_test_split(\n    temp_general, test_size=0.5, random_state=RANDOM_SEED\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:18:59.956379Z","iopub.execute_input":"2025-02-18T20:18:59.956710Z","iopub.status.idle":"2025-02-18T20:19:09.198977Z","shell.execute_reply.started":"2025-02-18T20:18:59.956680Z","shell.execute_reply":"2025-02-18T20:19:09.197944Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_general.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:19:28.903284Z","iopub.execute_input":"2025-02-18T20:19:28.903563Z","iopub.status.idle":"2025-02-18T20:19:28.909040Z","shell.execute_reply.started":"2025-02-18T20:19:28.903544Z","shell.execute_reply":"2025-02-18T20:19:28.908331Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(198680, 3)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"## Mistral Labeled 500 sentences\nmistral_labeled = pd.read_csv(\"/kaggle/input/nexign-original-data/comments_500_mistral_labeles_clear.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:19:09.200135Z","iopub.execute_input":"2025-02-18T20:19:09.200392Z","iopub.status.idle":"2025-02-18T20:19:09.216570Z","shell.execute_reply.started":"2025-02-18T20:19:09.200370Z","shell.execute_reply":"2025-02-18T20:19:09.215662Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"## Mistral Generated synth data\nsynth_val = pd.read_csv(\"/kaggle/input/new-nexign-data/test_synthetic (1).csv\")\nsynth_train = pd.read_csv(\"/kaggle/input/new-nexign-data/train_synthetic (1).csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:19:09.218018Z","iopub.execute_input":"2025-02-18T20:19:09.218263Z","iopub.status.idle":"2025-02-18T20:19:09.264903Z","shell.execute_reply.started":"2025-02-18T20:19:09.218243Z","shell.execute_reply":"2025-02-18T20:19:09.264292Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"len(synth_train) + len(synth_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:28:30.372636Z","iopub.execute_input":"2025-02-18T20:28:30.373131Z","iopub.status.idle":"2025-02-18T20:28:30.379781Z","shell.execute_reply.started":"2025-02-18T20:28:30.373090Z","shell.execute_reply":"2025-02-18T20:28:30.378910Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"4778"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"## Test data labeled by nexign\nclear_test = pd.read_csv(\"/kaggle/input/clear-test/comments_100.csv\")\nclear_test = clear_test.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:19:09.265699Z","iopub.execute_input":"2025-02-18T20:19:09.265968Z","iopub.status.idle":"2025-02-18T20:19:09.281041Z","shell.execute_reply.started":"2025-02-18T20:19:09.265936Z","shell.execute_reply":"2025-02-18T20:19:09.280357Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Datasets prep","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize(texts):\n    return tokenizer(\n        texts.tolist(),\n        padding=\"max_length\",\n        truncation=True,\n        max_length=MAX_LENGTH,\n        return_tensors=\"pt\"\n    )\n\nclass SentimentDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = torch.tensor(labels, dtype=torch.long)\n        \n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n            \"labels\": self.labels[idx]\n        }\n    \n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:18:45.136586Z","iopub.execute_input":"2025-02-18T17:18:45.136882Z","iopub.status.idle":"2025-02-18T17:18:46.634765Z","shell.execute_reply.started":"2025-02-18T17:18:45.136853Z","shell.execute_reply":"2025-02-18T17:18:46.634085Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7e1f149c4ea465397508bdcfa4f05bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf4aa99ec634c1cb2996424714b642e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c345103cb47849d9a2145cf0182f64b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/732 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"269ae55ef93a4b65b6cafdb0d8ba821e"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_general_encodings = tokenize(train_general[\"text\"].values)\ntest_general_encodings = tokenize(test_general[\"text\"].values)\nval_general_encodings = tokenize(val_general[\"text\"].values)\n\ntrain_general_dataset = SentimentDataset(train_general_encodings, train_general[\"sentiment\"].values)\nval_general_dataset = SentimentDataset(val_general_encodings, val_general[\"sentiment\"].values)\ntest_general_dataset = SentimentDataset(test_general_encodings, test_general[\"sentiment\"].values)\n\ntrain_general_loader = DataLoader(train_general_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_general_loader = DataLoader(val_general_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_general_loader = DataLoader(test_general_dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:18:46.636958Z","iopub.execute_input":"2025-02-18T17:18:46.637174Z","iopub.status.idle":"2025-02-18T17:20:44.705437Z","shell.execute_reply.started":"2025-02-18T17:18:46.637156Z","shell.execute_reply":"2025-02-18T17:20:44.704509Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"mistral_labeled_encodings = tokenize(mistral_labeled[\"MessageText\"].values)\nsynth_val_encodings = tokenize(synth_val[\"MessageText\"].values)\nsynth_train_encodings = tokenize(synth_train[\"MessageText\"].values)\nclear_test_encodings = tokenize(clear_test[\"MessageText\"].values)\n\nmistral_labeled_dataset = SentimentDataset(mistral_labeled_encodings, mistral_labeled[\"final_label\"].values)\nsynth_val_dataset = SentimentDataset(synth_val_encodings, synth_val[\"final_label\"].values)\nsynth_train_dataset = SentimentDataset(synth_train_encodings, synth_train[\"final_label\"].values)\nclear_test_dataset = SentimentDataset(clear_test_encodings, clear_test[\"Class\"].values)\n\nmistral_labeled_loader = DataLoader(mistral_labeled_dataset, batch_size=BATCH_SIZE, shuffle=True)\nsynth_val_loader = DataLoader(synth_val_dataset, batch_size=BATCH_SIZE, shuffle=True)\nsynth_train_loader = DataLoader(synth_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nclear_test_loader = DataLoader(clear_test_dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:20:44.707183Z","iopub.execute_input":"2025-02-18T17:20:44.707486Z","iopub.status.idle":"2025-02-18T17:20:47.757698Z","shell.execute_reply.started":"2025-02-18T17:20:44.707458Z","shell.execute_reply":"2025-02-18T17:20:47.756990Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Classes for training and evaluation","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass TrainingConfig:\n    batch_size: int = 16\n    epochs: int = 10\n    learning_rate: float = 2e-5\n    eps: float = 1e-8\n    warmup_ratio: float = 0.1\n    model_name: str = \"sergeyzh/rubert-tiny-turbo\"\n    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    output_dir: str = \"./output\"\n    grad_clip: float = 1.0\n\n    def create_output_dir(self):\n        \"\"\"Create the output directory if it does not exist.\"\"\"\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n            print(f\"Created output directory at {self.output_dir}\")\n\nclass SentimentDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = torch.tensor(labels, dtype=torch.long)\n        \n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n            \"labels\": self.labels[idx]\n        }\n    \n    def __len__(self):\n        return len(self.labels)\n\nclass ModelTrainer:\n    def __init__(self, model, train_loader, val_loader, config=TrainingConfig()):\n        self.model = model.to(config.device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.config = config\n        self.config.create_output_dir()\n        self.optimizer = AdamW(self.model.parameters(), lr=config.learning_rate, eps=config.eps)\n        self.scheduler = self._create_scheduler()\n        self.best_val_loss = float('inf')\n        self.metrics = []\n        self.class_weights = self._calculate_class_weights()\n        if self.class_weights is not None:\n            self.criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(config.device))\n        else:\n            self.criterion = None\n        \n    def _calculate_class_weights(self):\n        \"\"\"Calculate class weights from the training dataset.\"\"\"\n        labels = []\n        for batch in self.train_loader:\n            labels.extend(batch[\"labels\"].tolist())\n        class_weights = compute_class_weight(\"balanced\", classes=torch.unique(torch.tensor(labels)).tolist(), y=labels)\n        return torch.tensor(class_weights, dtype=torch.float32)\n    \n    def _create_scheduler(self):\n        total_steps = len(self.train_loader) * self.config.epochs\n        warmup_steps = int(total_steps * self.config.warmup_ratio)\n        return get_linear_schedule_with_warmup(\n            self.optimizer, \n            num_warmup_steps=warmup_steps,\n            num_training_steps=total_steps\n        )\n    \n    def train_epoch(self, epoch):\n        self.model.train()\n        epoch_loss = 0\n        progress_bar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.config.epochs} [Train]\")\n        \n        for batch in progress_bar:\n            self.optimizer.zero_grad()\n            inputs = self._prepare_inputs(batch)\n            outputs = self.model(**inputs)\n            logits = outputs.logits\n            labels = inputs[\"labels\"]\n            if self.criterion is not None:\n                loss = self.criterion(logits, labels)\n            else:\n                loss = outputs.loss\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clip)\n            self.optimizer.step()\n            self.scheduler.step()\n            \n            epoch_loss += loss.item()\n            progress_bar.set_postfix({\"loss\": loss.item()})\n            \n        return epoch_loss / len(self.train_loader)\n    \n    def validate(self):\n        self.model.eval()\n        epoch_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc=\"Validating\"):\n                inputs = self._prepare_inputs(batch)\n                outputs = self.model(**inputs)\n                logits = outputs.logits\n                labels = inputs[\"labels\"]\n                if self.criterion is not None:\n                    loss = self.criterion(logits, labels)\n                else:\n                    loss = outputs.loss\n                epoch_loss += loss.item()\n                \n                preds = torch.argmax(logits, dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_labels.extend(labels.cpu().numpy())\n                \n        avg_loss = epoch_loss / len(self.val_loader)\n        accuracy = accuracy_score(all_labels, all_preds)\n        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n        \n        return avg_loss, accuracy, f1\n    \n    def _prepare_inputs(self, batch):\n        return {\n            \"input_ids\": batch[\"input_ids\"].to(self.config.device),\n            \"attention_mask\": batch[\"attention_mask\"].to(self.config.device),\n            \"labels\": batch[\"labels\"].to(self.config.device)\n        }\n    \n    def train(self):\n        for epoch in range(self.config.epochs):\n            train_loss = self.train_epoch(epoch)\n            val_loss, val_acc, val_f1 = self.validate()\n            \n            self.metrics.append({\n                \"epoch\": epoch+1,\n                \"train_loss\": train_loss,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n                \"val_f1\": val_f1\n            })\n            \n            print(f\"\\nEpoch {epoch+1}/{self.config.epochs}\")\n            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n            print(f\"Val Accuracy: {val_acc:.4f} | Val F1: {val_f1:.4f}\\n\")\n            \n            if val_loss < self.best_val_loss:\n                self.best_val_loss = val_loss\n                self.save_model()\n                \n        self.plot_metrics()\n        self.save_metrics_to_excel()\n        return self.metrics\n    \n    def save_model(self):\n        torch.save(self.model.state_dict(), f\"{self.config.output_dir}/best_model.pt\")\n    \n    def plot_metrics(self):\n        try:\n            import matplotlib.pyplot as plt\n            plt.style.use('ggplot')\n        except ImportError:\n            print(\"Matplotlib is required to plot metrics. Please install it.\")\n            return\n\n        epochs = [m['epoch'] for m in self.metrics]\n        train_loss = [m['train_loss'] for m in self.metrics]\n        val_loss = [m['val_loss'] for m in self.metrics]\n        val_f1 = [m['val_f1'] for m in self.metrics]\n\n        fig, ax1 = plt.subplots(figsize=(10, 6))\n\n        color = 'tab:blue'\n        ax1.set_xlabel('Epoch')\n        ax1.set_ylabel('Loss', color=color)\n        ax1.plot(epochs, train_loss, label='Train Loss', color=color, linestyle='-', linewidth=2)\n        ax1.plot(epochs, val_loss, label='Val Loss', color='tab:orange', linestyle='-', linewidth=2)\n        ax1.tick_params(axis='y', labelcolor=color)\n        ax1.legend(loc='upper left')\n\n        ax2 = ax1.twinx()\n        color = 'tab:green'\n        ax2.set_ylabel('F1 Score', color=color)\n        ax2.plot(epochs, val_f1, label='Val F1', color=color, linestyle='--', linewidth=2)\n        ax2.tick_params(axis='y', labelcolor=color)\n        ax2.legend(loc='upper right')\n\n        plt.title('Training Loss, Validation Loss, and Validation F1 Score')\n        fig.tight_layout()\n        plt.savefig(os.path.join(self.config.output_dir, 'loss_f1_plot.png'), bbox_inches='tight', dpi=300)\n        plt.close()\n    \n    def save_metrics_to_excel(self):\n        \"\"\"Save training/validation metrics to an Excel file.\"\"\"\n        df = pd.DataFrame(self.metrics)\n        df.to_excel(os.path.join(self.config.output_dir, \"training_metrics.xlsx\"), index=False)\n        print(f\"Metrics saved to {os.path.join(self.config.output_dir, 'training_metrics.xlsx')}\")\n\nclass OutputLayerTrainer(ModelTrainer):\n    def __init__(self, model, train_loader, val_loader, config=TrainingConfig()):\n        super().__init__(model, train_loader, val_loader, config)\n        self._freeze_base_model()\n        \n    def _freeze_base_model(self):\n        for param in self.model.base_model.parameters():\n            param.requires_grad = False\n        for param in self.model.classifier.parameters():\n            param.requires_grad = True\n        print(\"Base model frozen. Only the output layer will be trained.\")\n    \n    def train(self):\n        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n        print(f\"Trainable parameters: {trainable_params}\")\n        return super().train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:20:47.758572Z","iopub.execute_input":"2025-02-18T17:20:47.758893Z","iopub.status.idle":"2025-02-18T17:20:47.782972Z","shell.execute_reply.started":"2025-02-18T17:20:47.758864Z","shell.execute_reply":"2025-02-18T17:20:47.782079Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class ModelEvaluator:\n    def __init__(self, model, test_loader, config=TrainingConfig()):\n        self.model = model.to(config.device)\n        self.test_loader = test_loader\n        self.config = config\n        self.config.create_output_dir()\n        self.class_names = ['NEUTRAL', 'POSITIVE', 'NEGATIVE']\n        \n    def evaluate(self):\n        self.model.eval()\n        test_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in tqdm(self.test_loader, desc=\"Testing\"):\n                inputs = {\n                    \"input_ids\": batch[\"input_ids\"].to(self.config.device),\n                    \"attention_mask\": batch[\"attention_mask\"].to(self.config.device),\n                    \"labels\": batch[\"labels\"].to(self.config.device)\n                }\n                outputs = self.model(**inputs)\n                loss = outputs.loss\n                test_loss += loss.item()\n                \n                logits = outputs.logits\n                preds = torch.argmax(logits, dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_labels.extend(inputs[\"labels\"].cpu().numpy())\n                \n        avg_loss = test_loss / len(self.test_loader)\n        metrics = self._calculate_metrics(avg_loss, all_labels, all_preds)\n        self._save_results(metrics, all_labels, all_preds)\n        return metrics\n    \n    def _calculate_metrics(self, avg_loss, true_labels, preds):\n        return {\n            \"test_loss\": avg_loss,\n            \"accuracy\": accuracy_score(true_labels, preds),\n            \"f1_weighted\": f1_score(true_labels, preds, average=\"weighted\"),\n            \"precision_macro\": precision_score(true_labels, preds, average='macro'),\n            \"recall_macro\": recall_score(true_labels, preds, average='macro'),\n            \"classification_report\": classification_report(true_labels, preds, target_names=self.class_names)\n        }\n    \n    def _save_results(self, metrics, true_labels, preds):\n        pd.DataFrame([metrics]).to_csv(f\"{self.config.output_dir}/test_metrics.csv\", index=False)\n        self._plot_confusion_matrix(true_labels, preds)\n        \n    def _plot_confusion_matrix(self, true_labels, preds):\n        cm = confusion_matrix(true_labels, preds)\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                    xticklabels=self.class_names, \n                    yticklabels=self.class_names)\n        plt.title('Confusion Matrix')\n        plt.xlabel('Predicted Label')\n        plt.ylabel('True Label')\n        plt.savefig(f\"{self.config.output_dir}/confusion_matrix.png\", bbox_inches='tight')\n        plt.close()\n\nclass ONNXExporter:\n    def __init__(self, model, tokenizer, config=TrainingConfig()):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.config = config\n        \n    def export(self, dummy_text=\"Пример текста\"):\n        class WrappedModel(torch.nn.Module):\n            def __init__(self, model):\n                super().__init__()\n                self.model = model\n\n            def forward(self, input_ids, attention_mask):\n                return self.model(input_ids, attention_mask).logits\n                \n        wrapped_model = WrappedModel(self.model).eval()\n        inputs = self.tokenizer(dummy_text, return_tensors=\"pt\")\n        \n        torch.onnx.export(\n            wrapped_model,\n            (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n            f\"{self.config.output_dir}/model.onnx\",\n            input_names=['input_ids', 'attention_mask'],\n            output_names=['logits'],\n            dynamic_axes={\n                'input_ids': {0: 'batch_size', 1: 'sequence_length'},\n                'attention_mask': {0: 'batch_size', 1: 'sequence_length'},\n                'logits': {0: 'batch_size'}\n            },\n            opset_version=14\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:20:47.784041Z","iopub.execute_input":"2025-02-18T17:20:47.784311Z","iopub.status.idle":"2025-02-18T17:20:47.805818Z","shell.execute_reply.started":"2025-02-18T17:20:47.784286Z","shell.execute_reply":"2025-02-18T17:20:47.805074Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Training base model","metadata":{}},{"cell_type":"code","source":"config_general = TrainingConfig(output_dir=\"./general_model/\")\nmodel = AutoModelForSequenceClassification.from_pretrained(config_general.model_name, num_labels=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:20:47.806672Z","iopub.execute_input":"2025-02-18T17:20:47.806865Z","iopub.status.idle":"2025-02-18T17:21:03.783616Z","shell.execute_reply.started":"2025-02-18T17:20:47.806847Z","shell.execute_reply":"2025-02-18T17:21:03.782747Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"febf4cc60ff3406581b9c881cb77b522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/117M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1d020473c3344e48af5b9d4b7edfbc9"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sergeyzh/rubert-tiny-turbo and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#trainer = ModelTrainer(model, train_general_loader, val_general_loader, config_general)\n#metrics = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:21:03.784842Z","iopub.execute_input":"2025-02-18T17:21:03.785525Z","iopub.status.idle":"2025-02-18T17:21:03.788847Z","shell.execute_reply.started":"2025-02-18T17:21:03.785493Z","shell.execute_reply":"2025-02-18T17:21:03.788069Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"/kaggle/input/best_model_nxign/pytorch/default/1/best_model.pt\"))\nevaluator = ModelEvaluator(model, test_general_loader, config_general)\ntest_metrics = evaluator.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:21:03.789556Z","iopub.execute_input":"2025-02-18T17:21:03.789842Z","iopub.status.idle":"2025-02-18T17:22:13.986009Z","shell.execute_reply.started":"2025-02-18T17:21:03.789822Z","shell.execute_reply":"2025-02-18T17:22:13.985319Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-14-b520ed4323d3>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/input/best_model_nxign/pytorch/default/1/best_model.pt\"))\n","output_type":"stream"},{"name":"stdout","text":"Created output directory at ./general_model/\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 1554/1554 [01:07<00:00, 22.92it/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def print_test_metrics(metrics):\n    for i in metrics.keys():\n        if i!=\"classification_report\":\n            print(f\"{i}: {metrics[i]}\")\n        else:\n            print(f\"{i}\")\n            print(f\"{metrics[i]}\")\n\nprint_test_metrics(test_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:22:13.987003Z","iopub.execute_input":"2025-02-18T17:22:13.987306Z","iopub.status.idle":"2025-02-18T17:22:13.992653Z","shell.execute_reply.started":"2025-02-18T17:22:13.987278Z","shell.execute_reply":"2025-02-18T17:22:13.991767Z"}},"outputs":[{"name":"stdout","text":"test_loss: 0.4268440281926742\naccuracy: 0.8149668074834038\nf1_weighted: 0.8135819989080717\nprecision_macro: 0.8003812232810521\nrecall_macro: 0.7999252540211469\nclassification_report\n              precision    recall  f1-score   support\n\n     NEUTRAL       0.72      0.67      0.70      6064\n    POSITIVE       0.85      0.85      0.85     12227\n    NEGATIVE       0.83      0.87      0.85      6564\n\n    accuracy                           0.81     24855\n   macro avg       0.80      0.80      0.80     24855\nweighted avg       0.81      0.81      0.81     24855\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"config_general = TrainingConfig(output_dir=\"./general_model_on_clear_data/\")\nevaluator = ModelEvaluator(model, clear_test_loader, config_general)\ntest_metrics_clear = evaluator.evaluate()\n\nprint_test_metrics(test_metrics_clear)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:22:13.993340Z","iopub.execute_input":"2025-02-18T17:22:13.993533Z","iopub.status.idle":"2025-02-18T17:22:14.530318Z","shell.execute_reply.started":"2025-02-18T17:22:13.993516Z","shell.execute_reply":"2025-02-18T17:22:14.529543Z"}},"outputs":[{"name":"stdout","text":"Created output directory at ./general_model_on_clear_data/\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"test_loss: 1.0221395918301173\naccuracy: 0.5858585858585859\nf1_weighted: 0.6084933394897443\nprecision_macro: 0.5280492898913952\nrecall_macro: 0.5507271002364669\nclassification_report\n              precision    recall  f1-score   support\n\n     NEUTRAL       0.42      0.76      0.54        21\n    POSITIVE       0.93      0.63      0.75        59\n    NEGATIVE       0.24      0.26      0.25        19\n\n    accuracy                           0.59        99\n   macro avg       0.53      0.55      0.51        99\nweighted avg       0.69      0.59      0.61        99\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"config_synth= TrainingConfig(output_dir=\"./synth_model/\")\nmodel.load_state_dict(torch.load(f\"/kaggle/input/best_model_nxign/pytorch/default/1/best_model.pt\"))\ntrainer = ModelTrainer(model, synth_train_loader, synth_val_loader, config_synth)\nmetrics = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:22:14.531213Z","iopub.execute_input":"2025-02-18T17:22:14.531555Z","iopub.status.idle":"2025-02-18T17:30:57.988501Z","shell.execute_reply.started":"2025-02-18T17:22:14.531521Z","shell.execute_reply":"2025-02-18T17:30:57.987792Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-17-0bb371362b3b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/input/best_model_nxign/pytorch/default/1/best_model.pt\"))\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Created output directory at ./synth_model/\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.32it/s, loss=0.939]\nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 1.2336 | Val Loss: 0.8258\nVal Accuracy: 0.6491 | Val F1: 0.6547\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.651]\nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/10\nTrain Loss: 0.6950 | Val Loss: 0.7878\nVal Accuracy: 0.6954 | Val F1: 0.7009\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.738]\nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/10\nTrain Loss: 0.5274 | Val Loss: 0.8853\nVal Accuracy: 0.7263 | Val F1: 0.7238\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.39] \nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/10\nTrain Loss: 0.4160 | Val Loss: 0.9583\nVal Accuracy: 0.7102 | Val F1: 0.7099\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.139] \nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/10\nTrain Loss: 0.3307 | Val Loss: 1.0475\nVal Accuracy: 0.7074 | Val F1: 0.7064\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.136] \nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/10\nTrain Loss: 0.2657 | Val Loss: 1.1763\nVal Accuracy: 0.7039 | Val F1: 0.7031\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.255] \nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/10\nTrain Loss: 0.2170 | Val Loss: 1.2222\nVal Accuracy: 0.7074 | Val F1: 0.7059\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.0184]\nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/10\nTrain Loss: 0.1900 | Val Loss: 1.2925\nVal Accuracy: 0.7053 | Val F1: 0.7030\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.0519]\nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/10\nTrain Loss: 0.1766 | Val Loss: 1.3546\nVal Accuracy: 0.7067 | Val F1: 0.7042\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]: 100%|██████████| 210/210 [00:48<00:00,  4.35it/s, loss=0.0231]\nValidating: 100%|██████████| 90/90 [00:03<00:00, 23.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/10\nTrain Loss: 0.1504 | Val Loss: 1.3374\nVal Accuracy: 0.7060 | Val F1: 0.7036\n\nMetrics saved to ./synth_model/training_metrics.xlsx\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"/kaggle/working/synth_model/best_model.pt\"))\nevaluator = ModelEvaluator(model, mistral_labeled_loader, config_synth)\ntest_metrics_synth = evaluator.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:30:57.989341Z","iopub.execute_input":"2025-02-18T17:30:57.989855Z","iopub.status.idle":"2025-02-18T17:30:59.687635Z","shell.execute_reply.started":"2025-02-18T17:30:57.989830Z","shell.execute_reply":"2025-02-18T17:30:59.686988Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-cd9baa6e71ab>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/working/synth_model/best_model.pt\"))\nTesting: 100%|██████████| 32/32 [00:01<00:00, 23.38it/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print_test_metrics(test_metrics_synth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:30:59.688405Z","iopub.execute_input":"2025-02-18T17:30:59.688622Z","iopub.status.idle":"2025-02-18T17:30:59.693374Z","shell.execute_reply.started":"2025-02-18T17:30:59.688604Z","shell.execute_reply":"2025-02-18T17:30:59.692724Z"}},"outputs":[{"name":"stdout","text":"test_loss: 0.6477523595094681\naccuracy: 0.7267326732673267\nf1_weighted: 0.7330365598786713\nprecision_macro: 0.6925221772223368\nrecall_macro: 0.7153144870910902\nclassification_report\n              precision    recall  f1-score   support\n\n     NEUTRAL       0.74      0.72      0.73       229\n    POSITIVE       0.85      0.75      0.80       200\n    NEGATIVE       0.49      0.67      0.56        76\n\n    accuracy                           0.73       505\n   macro avg       0.69      0.72      0.70       505\nweighted avg       0.75      0.73      0.73       505\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"config_synth.output_dir = \"./synth_model_on_clear\"\nmodel.load_state_dict(torch.load(f\"/kaggle/working/synth_model/best_model.pt\"))\nevaluator = ModelEvaluator(model, clear_test_loader, config_synth)\ntest_metrics_synth_on_clear = evaluator.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:30:59.694194Z","iopub.execute_input":"2025-02-18T17:30:59.694404Z","iopub.status.idle":"2025-02-18T17:31:00.291872Z","shell.execute_reply.started":"2025-02-18T17:30:59.694387Z","shell.execute_reply":"2025-02-18T17:31:00.291187Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-20-902bd5acc465>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/working/synth_model/best_model.pt\"))\n","output_type":"stream"},{"name":"stdout","text":"Created output directory at ./synth_model_on_clear\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print_test_metrics(test_metrics_synth_on_clear)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:31:00.292638Z","iopub.execute_input":"2025-02-18T17:31:00.292929Z","iopub.status.idle":"2025-02-18T17:31:00.298203Z","shell.execute_reply.started":"2025-02-18T17:31:00.292904Z","shell.execute_reply":"2025-02-18T17:31:00.297330Z"}},"outputs":[{"name":"stdout","text":"test_loss: 0.3688892956290926\naccuracy: 0.8585858585858586\nf1_weighted: 0.8531090960758482\nprecision_macro: 0.8206576850644648\nrecall_macro: 0.8067768290783456\nclassification_report\n              precision    recall  f1-score   support\n\n     NEUTRAL       0.85      0.52      0.65        21\n    POSITIVE       0.95      0.95      0.95        59\n    NEGATIVE       0.67      0.95      0.78        19\n\n    accuracy                           0.86        99\n   macro avg       0.82      0.81      0.79        99\nweighted avg       0.87      0.86      0.85        99\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Tuning classificator head","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"/kaggle/input/best_model_nxign/pytorch/default/1/best_model.pt\"))\nconfig_output_general = TrainingConfig(output_dir = \"./general_output_tuning\",\n                                        epochs=100,\n                                        learning_rate=1e-4,\n                                        warmup_ratio=0.0,\n                                        grad_clip=1.0   \n                                      )\n\noutput_layer_trainer = OutputLayerTrainer(model, mistral_labeled_loader, clear_test_loader, config_output_general)\nmetrics = output_layer_trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:31:00.299019Z","iopub.execute_input":"2025-02-18T17:31:00.299295Z","iopub.status.idle":"2025-02-18T17:34:27.143384Z","shell.execute_reply.started":"2025-02-18T17:31:00.299269Z","shell.execute_reply":"2025-02-18T17:34:27.142629Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-22-87f5c1297473>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/input/best_model_nxign/pytorch/default/1/best_model.pt\"))\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Created output directory at ./general_output_tuning\nBase model frozen. Only the output layer will be trained.\nTrainable parameters: 939\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.963]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/100\nTrain Loss: 1.5019 | Val Loss: 1.0385\nVal Accuracy: 0.6162 | Val F1: 0.6381\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=1.7]  \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/100\nTrain Loss: 1.3483 | Val Loss: 0.8825\nVal Accuracy: 0.6566 | Val F1: 0.6756\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.941]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/100\nTrain Loss: 1.2177 | Val Loss: 0.7900\nVal Accuracy: 0.6566 | Val F1: 0.6756\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=0.496]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/100\nTrain Loss: 1.0979 | Val Loss: 0.7621\nVal Accuracy: 0.6768 | Val F1: 0.6965\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.21it/s, loss=1.2]  \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/100\nTrain Loss: 1.0479 | Val Loss: 0.7300\nVal Accuracy: 0.7071 | Val F1: 0.7231\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=1.4]  \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/100\nTrain Loss: 1.0021 | Val Loss: 0.6825\nVal Accuracy: 0.7374 | Val F1: 0.7507\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.851]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/100\nTrain Loss: 0.9834 | Val Loss: 0.6723\nVal Accuracy: 0.7778 | Val F1: 0.7868\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.563]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/100\nTrain Loss: 0.9537 | Val Loss: 0.6739\nVal Accuracy: 0.7778 | Val F1: 0.7868\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.704]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/100\nTrain Loss: 0.9413 | Val Loss: 0.6165\nVal Accuracy: 0.7879 | Val F1: 0.7957\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=0.709]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/100\nTrain Loss: 0.9178 | Val Loss: 0.6515\nVal Accuracy: 0.7778 | Val F1: 0.7846\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=1.14] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/100\nTrain Loss: 0.9109 | Val Loss: 0.5772\nVal Accuracy: 0.7778 | Val F1: 0.7846\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.601]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/100\nTrain Loss: 0.8814 | Val Loss: 0.6532\nVal Accuracy: 0.7980 | Val F1: 0.8016\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=1.01] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/100\nTrain Loss: 0.8842 | Val Loss: 0.5729\nVal Accuracy: 0.7980 | Val F1: 0.8016\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=1.04] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/100\nTrain Loss: 0.9029 | Val Loss: 0.5802\nVal Accuracy: 0.8081 | Val F1: 0.8101\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.32it/s, loss=0.825]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/100\nTrain Loss: 0.8936 | Val Loss: 0.5814\nVal Accuracy: 0.8081 | Val F1: 0.8101\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=0.814]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16/100\nTrain Loss: 0.8916 | Val Loss: 0.5680\nVal Accuracy: 0.8081 | Val F1: 0.8101\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=1.09] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17/100\nTrain Loss: 0.8897 | Val Loss: 0.5903\nVal Accuracy: 0.8182 | Val F1: 0.8204\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.81] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18/100\nTrain Loss: 0.8652 | Val Loss: 0.5397\nVal Accuracy: 0.8081 | Val F1: 0.8079\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.825]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19/100\nTrain Loss: 0.8663 | Val Loss: 0.6199\nVal Accuracy: 0.8081 | Val F1: 0.8079\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=1.1]  \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20/100\nTrain Loss: 0.8663 | Val Loss: 0.5701\nVal Accuracy: 0.8081 | Val F1: 0.8079\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.807]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21/100\nTrain Loss: 0.8657 | Val Loss: 0.5827\nVal Accuracy: 0.8081 | Val F1: 0.8079\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=0.793]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22/100\nTrain Loss: 0.8578 | Val Loss: 0.5646\nVal Accuracy: 0.8081 | Val F1: 0.8079\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.34it/s, loss=0.703]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23/100\nTrain Loss: 0.8654 | Val Loss: 0.5503\nVal Accuracy: 0.8081 | Val F1: 0.8053\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.818]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24/100\nTrain Loss: 0.8697 | Val Loss: 0.6575\nVal Accuracy: 0.8081 | Val F1: 0.8038\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.36it/s, loss=0.875]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25/100\nTrain Loss: 0.8617 | Val Loss: 0.5590\nVal Accuracy: 0.8182 | Val F1: 0.8148\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.723]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26/100\nTrain Loss: 0.8482 | Val Loss: 0.6033\nVal Accuracy: 0.8182 | Val F1: 0.8148\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.842]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27/100\nTrain Loss: 0.8328 | Val Loss: 0.5782\nVal Accuracy: 0.8081 | Val F1: 0.8038\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=1.06] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28/100\nTrain Loss: 0.8312 | Val Loss: 0.6125\nVal Accuracy: 0.8182 | Val F1: 0.8148\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.29it/s, loss=0.579]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29/100\nTrain Loss: 0.8490 | Val Loss: 0.5822\nVal Accuracy: 0.8081 | Val F1: 0.8038\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.716]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30/100\nTrain Loss: 0.8526 | Val Loss: 0.5663\nVal Accuracy: 0.7980 | Val F1: 0.7925\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.761]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31/100\nTrain Loss: 0.8475 | Val Loss: 0.5534\nVal Accuracy: 0.7980 | Val F1: 0.7925\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.47it/s, loss=1.15] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32/100\nTrain Loss: 0.8561 | Val Loss: 0.5735\nVal Accuracy: 0.7980 | Val F1: 0.7925\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=1.14] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33/100\nTrain Loss: 0.8458 | Val Loss: 0.6310\nVal Accuracy: 0.7980 | Val F1: 0.7913\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.33it/s, loss=0.981]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34/100\nTrain Loss: 0.8407 | Val Loss: 0.5413\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.856]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35/100\nTrain Loss: 0.8332 | Val Loss: 0.5747\nVal Accuracy: 0.7879 | Val F1: 0.7800\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=1.28] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 36/100\nTrain Loss: 0.8533 | Val Loss: 0.5419\nVal Accuracy: 0.7980 | Val F1: 0.7913\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.47it/s, loss=0.483]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 37/100\nTrain Loss: 0.8292 | Val Loss: 0.5398\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.37it/s, loss=0.863]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 38/100\nTrain Loss: 0.8470 | Val Loss: 0.5612\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.678]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 39/100\nTrain Loss: 0.8361 | Val Loss: 0.5620\nVal Accuracy: 0.7980 | Val F1: 0.7913\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.949]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 40/100\nTrain Loss: 0.8331 | Val Loss: 0.5354\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.994]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 41/100\nTrain Loss: 0.8148 | Val Loss: 0.6228\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.713]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 42/100\nTrain Loss: 0.8172 | Val Loss: 0.5526\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=0.769]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 43/100\nTrain Loss: 0.8362 | Val Loss: 0.5136\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.831]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 44/100\nTrain Loss: 0.8192 | Val Loss: 0.6011\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.47it/s, loss=0.663]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 45/100\nTrain Loss: 0.8284 | Val Loss: 0.6430\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.792]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 46/100\nTrain Loss: 0.8212 | Val Loss: 0.5025\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=0.671]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 47/100\nTrain Loss: 0.8188 | Val Loss: 0.5632\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.37it/s, loss=0.744]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 48/100\nTrain Loss: 0.8116 | Val Loss: 0.5606\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.779]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 49/100\nTrain Loss: 0.8385 | Val Loss: 0.5922\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.48it/s, loss=0.939]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 50/100\nTrain Loss: 0.8132 | Val Loss: 0.5619\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.851]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 51/100\nTrain Loss: 0.8262 | Val Loss: 0.5279\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=1.18] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 52/100\nTrain Loss: 0.8145 | Val Loss: 0.5494\nVal Accuracy: 0.8081 | Val F1: 0.8023\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.669]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 53/100\nTrain Loss: 0.8178 | Val Loss: 0.5331\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=1.04] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 54/100\nTrain Loss: 0.8106 | Val Loss: 0.5819\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.48it/s, loss=0.983]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 55/100\nTrain Loss: 0.8214 | Val Loss: 0.5426\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.34it/s, loss=0.948]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 56/100\nTrain Loss: 0.8162 | Val Loss: 0.5135\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.569]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 57/100\nTrain Loss: 0.8245 | Val Loss: 0.5253\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=1.52] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 58/100\nTrain Loss: 0.8291 | Val Loss: 0.5217\nVal Accuracy: 0.7980 | Val F1: 0.7873\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.666]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 59/100\nTrain Loss: 0.8103 | Val Loss: 0.5218\nVal Accuracy: 0.7980 | Val F1: 0.7873\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.797]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 60/100\nTrain Loss: 0.8163 | Val Loss: 0.5362\nVal Accuracy: 0.7980 | Val F1: 0.7873\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.867]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 61/100\nTrain Loss: 0.8353 | Val Loss: 0.5206\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.626]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 62/100\nTrain Loss: 0.8100 | Val Loss: 0.5292\nVal Accuracy: 0.7980 | Val F1: 0.7873\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=0.85] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 63/100\nTrain Loss: 0.8019 | Val Loss: 0.5400\nVal Accuracy: 0.7980 | Val F1: 0.7873\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.495]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 64/100\nTrain Loss: 0.7944 | Val Loss: 0.5402\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.678]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 65/100\nTrain Loss: 0.8021 | Val Loss: 0.5653\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.24it/s, loss=0.679]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 66/100\nTrain Loss: 0.8251 | Val Loss: 0.5446\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.31it/s, loss=0.835]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 67/100\nTrain Loss: 0.8137 | Val Loss: 0.5663\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.681]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 68/100\nTrain Loss: 0.8088 | Val Loss: 0.5135\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.47it/s, loss=0.566]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 69/100\nTrain Loss: 0.8038 | Val Loss: 0.5597\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=0.668]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 70/100\nTrain Loss: 0.8097 | Val Loss: 0.5932\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.75] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 71/100\nTrain Loss: 0.8180 | Val Loss: 0.6553\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=1.09] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 72/100\nTrain Loss: 0.8152 | Val Loss: 0.5319\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.626]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 73/100\nTrain Loss: 0.8033 | Val Loss: 0.5288\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.32it/s, loss=0.706]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 74/100\nTrain Loss: 0.8092 | Val Loss: 0.4893\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=0.506]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 75/100\nTrain Loss: 0.8010 | Val Loss: 0.5436\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.813]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 76/100\nTrain Loss: 0.8155 | Val Loss: 0.6193\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.718]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 77/100\nTrain Loss: 0.8111 | Val Loss: 0.5659\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=0.757]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 78/100\nTrain Loss: 0.8073 | Val Loss: 0.5228\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.903]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 79/100\nTrain Loss: 0.8176 | Val Loss: 0.5638\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 80/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.36it/s, loss=0.563]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 80/100\nTrain Loss: 0.8090 | Val Loss: 0.5441\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=0.79] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 81/100\nTrain Loss: 0.8000 | Val Loss: 0.5514\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 82/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.957]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 82/100\nTrain Loss: 0.7910 | Val Loss: 0.5837\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 83/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.841]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 83/100\nTrain Loss: 0.8024 | Val Loss: 0.5665\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 84/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.658]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 84/100\nTrain Loss: 0.8037 | Val Loss: 0.5423\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 85/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.31it/s, loss=0.86] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 85/100\nTrain Loss: 0.8142 | Val Loss: 0.5458\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.699]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 86/100\nTrain Loss: 0.8061 | Val Loss: 0.5638\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 87/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.22it/s, loss=0.838]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 87/100\nTrain Loss: 0.8204 | Val Loss: 0.5050\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 88/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.46it/s, loss=0.924]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 88/100\nTrain Loss: 0.7993 | Val Loss: 0.5263\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.535]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 89/100\nTrain Loss: 0.8071 | Val Loss: 0.5103\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 90/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.915]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 90/100\nTrain Loss: 0.8089 | Val Loss: 0.6051\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 91/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=1]    \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 91/100\nTrain Loss: 0.8178 | Val Loss: 0.5251\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 92/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.32it/s, loss=0.858]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 92/100\nTrain Loss: 0.7964 | Val Loss: 0.5352\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 93/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.36it/s, loss=0.666]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 93/100\nTrain Loss: 0.7992 | Val Loss: 0.5536\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 94/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.876]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 94/100\nTrain Loss: 0.8087 | Val Loss: 0.5553\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 95/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.601]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 95/100\nTrain Loss: 0.7847 | Val Loss: 0.5890\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 96/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.776]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 96/100\nTrain Loss: 0.7973 | Val Loss: 0.5601\nVal Accuracy: 0.8081 | Val F1: 0.7993\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 97/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=1.25] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 97/100\nTrain Loss: 0.8029 | Val Loss: 0.4942\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 98/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.746]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 98/100\nTrain Loss: 0.7868 | Val Loss: 0.5434\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 99/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.27it/s, loss=1.02] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 99/100\nTrain Loss: 0.8032 | Val Loss: 0.5091\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 100/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.36it/s, loss=1.03] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 100/100\nTrain Loss: 0.8102 | Val Loss: 0.5604\nVal Accuracy: 0.8182 | Val F1: 0.8110\n\nMetrics saved to ./general_output_tuning/training_metrics.xlsx\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"/kaggle/working/general_output_tuning/best_model.pt\"))\nevaluator = ModelEvaluator(model, clear_test_loader, config_output_general)\ntest_metrics_output_general_on_clear = evaluator.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:34:27.146066Z","iopub.execute_input":"2025-02-18T17:34:27.146300Z","iopub.status.idle":"2025-02-18T17:34:27.727843Z","shell.execute_reply.started":"2025-02-18T17:34:27.146281Z","shell.execute_reply":"2025-02-18T17:34:27.726951Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-23-943bc47b5c46>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/working/general_output_tuning/best_model.pt\"))\nTesting: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print_test_metrics(test_metrics_output_general_on_clear)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:34:27.729153Z","iopub.execute_input":"2025-02-18T17:34:27.729465Z","iopub.status.idle":"2025-02-18T17:34:27.735161Z","shell.execute_reply.started":"2025-02-18T17:34:27.729431Z","shell.execute_reply":"2025-02-18T17:34:27.734322Z"}},"outputs":[{"name":"stdout","text":"test_loss: 0.4912905182157244\naccuracy: 0.8181818181818182\nf1_weighted: 0.8110247126640567\nprecision_macro: 0.7587962962962962\nrecall_macro: 0.7366013904818544\nclassification_report\n              precision    recall  f1-score   support\n\n     NEUTRAL       0.69      0.52      0.59        21\n    POSITIVE       0.89      0.95      0.92        59\n    NEGATIVE       0.70      0.74      0.72        19\n\n    accuracy                           0.82        99\n   macro avg       0.76      0.74      0.74        99\nweighted avg       0.81      0.82      0.81        99\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"/kaggle/working/synth_model/best_model.pt\"))\nconfig_output_general.output_dir = \"./synth_output_tuning\"\noutput_layer_trainer = OutputLayerTrainer(model, mistral_labeled_loader, clear_test_loader, config_output_general)\nmetrics = output_layer_trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:34:27.736002Z","iopub.execute_input":"2025-02-18T17:34:27.736258Z","iopub.status.idle":"2025-02-18T17:37:51.330576Z","shell.execute_reply.started":"2025-02-18T17:34:27.736229Z","shell.execute_reply":"2025-02-18T17:37:51.329684Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-25-9b80a051612f>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/working/synth_model/best_model.pt\"))\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Created output directory at ./synth_output_tuning\nBase model frozen. Only the output layer will be trained.\nTrainable parameters: 939\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.344]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/100\nTrain Loss: 0.6990 | Val Loss: 0.3539\nVal Accuracy: 0.8586 | Val F1: 0.8531\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.37it/s, loss=1.42] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/100\nTrain Loss: 0.7078 | Val Loss: 0.3601\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=0.995]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/100\nTrain Loss: 0.6863 | Val Loss: 0.3579\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.547]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/100\nTrain Loss: 0.6967 | Val Loss: 0.3667\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.449]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/100\nTrain Loss: 0.6939 | Val Loss: 0.3698\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.784]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/100\nTrain Loss: 0.6587 | Val Loss: 0.3629\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.391]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/100\nTrain Loss: 0.6776 | Val Loss: 0.3503\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.416]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/100\nTrain Loss: 0.6757 | Val Loss: 0.4019\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.33it/s, loss=0.459]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/100\nTrain Loss: 0.6837 | Val Loss: 0.4543\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.655]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/100\nTrain Loss: 0.6695 | Val Loss: 0.6126\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=1.03] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/100\nTrain Loss: 0.6608 | Val Loss: 0.3813\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=0.744]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/100\nTrain Loss: 0.6467 | Val Loss: 0.3284\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.574]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/100\nTrain Loss: 0.6568 | Val Loss: 0.4067\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.701]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/100\nTrain Loss: 0.6777 | Val Loss: 0.3658\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=1.03] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/100\nTrain Loss: 0.6569 | Val Loss: 0.3865\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.33it/s, loss=0.681]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16/100\nTrain Loss: 0.6569 | Val Loss: 0.3730\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.18it/s, loss=0.502]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17/100\nTrain Loss: 0.6560 | Val Loss: 0.3468\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.408]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18/100\nTrain Loss: 0.6592 | Val Loss: 0.3864\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.76] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19/100\nTrain Loss: 0.6776 | Val Loss: 0.3794\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=1.11] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20/100\nTrain Loss: 0.6652 | Val Loss: 0.3411\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.379]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21/100\nTrain Loss: 0.6625 | Val Loss: 0.4182\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=1.42] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22/100\nTrain Loss: 0.6459 | Val Loss: 0.4162\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=1.17] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23/100\nTrain Loss: 0.6498 | Val Loss: 0.4324\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=1.15] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24/100\nTrain Loss: 0.6574 | Val Loss: 0.3818\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.141]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25/100\nTrain Loss: 0.6556 | Val Loss: 0.4721\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.539]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26/100\nTrain Loss: 0.6388 | Val Loss: 0.3639\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.486]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27/100\nTrain Loss: 0.6526 | Val Loss: 0.3506\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.559]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28/100\nTrain Loss: 0.6538 | Val Loss: 0.3426\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.422]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29/100\nTrain Loss: 0.6760 | Val Loss: 0.3699\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.33it/s, loss=0.578]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30/100\nTrain Loss: 0.6632 | Val Loss: 0.3862\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=0.364]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31/100\nTrain Loss: 0.6426 | Val Loss: 0.3811\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.571]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32/100\nTrain Loss: 0.6699 | Val Loss: 0.3727\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.478]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33/100\nTrain Loss: 0.6557 | Val Loss: 0.3937\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.339]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34/100\nTrain Loss: 0.6654 | Val Loss: 0.4111\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.27it/s, loss=0.543]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35/100\nTrain Loss: 0.6639 | Val Loss: 0.3429\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.412]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 36/100\nTrain Loss: 0.6499 | Val Loss: 0.4004\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.592]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 37/100\nTrain Loss: 0.6585 | Val Loss: 0.3702\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.511]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 38/100\nTrain Loss: 0.6481 | Val Loss: 0.3799\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.597]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 39/100\nTrain Loss: 0.6350 | Val Loss: 0.3712\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=1.33] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 40/100\nTrain Loss: 0.6364 | Val Loss: 0.4669\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.518]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 41/100\nTrain Loss: 0.6623 | Val Loss: 0.3563\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.31it/s, loss=0.479]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 42/100\nTrain Loss: 0.6436 | Val Loss: 0.3825\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.37it/s, loss=0.746]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 43/100\nTrain Loss: 0.6468 | Val Loss: 0.3796\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.403]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 44/100\nTrain Loss: 0.6704 | Val Loss: 0.3863\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.34it/s, loss=0.898]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 45/100\nTrain Loss: 0.6406 | Val Loss: 0.3460\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.464]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 46/100\nTrain Loss: 0.6683 | Val Loss: 0.4181\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.392]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 47/100\nTrain Loss: 0.6637 | Val Loss: 0.3674\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.29it/s, loss=0.448]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 48/100\nTrain Loss: 0.6631 | Val Loss: 0.3567\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=1.05] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 49/100\nTrain Loss: 0.6573 | Val Loss: 0.5225\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.39it/s, loss=0.474]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 50/100\nTrain Loss: 0.6429 | Val Loss: 0.4671\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.462]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 51/100\nTrain Loss: 0.6421 | Val Loss: 0.3832\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.807]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 52/100\nTrain Loss: 0.6674 | Val Loss: 0.3621\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.32it/s, loss=0.756]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 53/100\nTrain Loss: 0.6294 | Val Loss: 0.4280\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=1]    \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 54/100\nTrain Loss: 0.6550 | Val Loss: 0.3642\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.54] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 55/100\nTrain Loss: 0.6393 | Val Loss: 0.3643\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.603]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 56/100\nTrain Loss: 0.6458 | Val Loss: 0.3594\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.455]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 57/100\nTrain Loss: 0.6484 | Val Loss: 0.4353\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.776]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 58/100\nTrain Loss: 0.6559 | Val Loss: 0.3313\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.294]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 59/100\nTrain Loss: 0.6344 | Val Loss: 0.3569\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=0.893]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 60/100\nTrain Loss: 0.6590 | Val Loss: 0.4144\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.342]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 61/100\nTrain Loss: 0.6448 | Val Loss: 0.3443\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.36it/s, loss=0.564]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 62/100\nTrain Loss: 0.6538 | Val Loss: 0.3901\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.25it/s, loss=0.59] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 63/100\nTrain Loss: 0.6571 | Val Loss: 0.3983\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.825]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 64/100\nTrain Loss: 0.6460 | Val Loss: 0.3649\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.274]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 65/100\nTrain Loss: 0.6267 | Val Loss: 0.3967\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.42it/s, loss=0.84] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 66/100\nTrain Loss: 0.6630 | Val Loss: 0.3562\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.29it/s, loss=0.511]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 67/100\nTrain Loss: 0.6313 | Val Loss: 0.3655\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.33it/s, loss=0.284]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 68/100\nTrain Loss: 0.6181 | Val Loss: 0.3721\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.423]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 69/100\nTrain Loss: 0.6462 | Val Loss: 0.3524\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.288]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 70/100\nTrain Loss: 0.6293 | Val Loss: 0.3617\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.265]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 71/100\nTrain Loss: 0.6452 | Val Loss: 0.3812\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.661]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 72/100\nTrain Loss: 0.6494 | Val Loss: 0.3445\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.42] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 73/100\nTrain Loss: 0.6321 | Val Loss: 0.4014\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=0.767]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 74/100\nTrain Loss: 0.6645 | Val Loss: 0.3511\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=1.01] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 75/100\nTrain Loss: 0.6607 | Val Loss: 0.3748\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.63] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 76/100\nTrain Loss: 0.6301 | Val Loss: 0.3925\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.349]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 77/100\nTrain Loss: 0.6512 | Val Loss: 0.3744\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.618]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 78/100\nTrain Loss: 0.6496 | Val Loss: 0.3564\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.34it/s, loss=0.384]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 79/100\nTrain Loss: 0.6380 | Val Loss: 0.3683\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 80/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=1.47] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 80/100\nTrain Loss: 0.6473 | Val Loss: 0.3584\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=0.544]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 81/100\nTrain Loss: 0.6357 | Val Loss: 0.3744\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 82/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.36it/s, loss=0.599]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 82/100\nTrain Loss: 0.6503 | Val Loss: 0.3497\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 83/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=1.02] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 83/100\nTrain Loss: 0.6406 | Val Loss: 0.4332\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 84/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.45it/s, loss=0.345]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 84/100\nTrain Loss: 0.6516 | Val Loss: 0.3874\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 85/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.28it/s, loss=0.518]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 85/100\nTrain Loss: 0.6430 | Val Loss: 0.3543\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=0.584]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 86/100\nTrain Loss: 0.6487 | Val Loss: 0.3798\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 87/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.443]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 87/100\nTrain Loss: 0.6436 | Val Loss: 0.3714\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 88/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.763]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 88/100\nTrain Loss: 0.6459 | Val Loss: 0.3692\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.721]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 89/100\nTrain Loss: 0.6399 | Val Loss: 0.4304\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 90/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.37it/s, loss=0.571]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 90/100\nTrain Loss: 0.6366 | Val Loss: 0.3512\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 91/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.41] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 91/100\nTrain Loss: 0.6379 | Val Loss: 0.3474\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 92/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.35it/s, loss=0.591]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 92/100\nTrain Loss: 0.6586 | Val Loss: 0.4125\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 93/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.27it/s, loss=0.633]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 93/100\nTrain Loss: 0.6289 | Val Loss: 0.3999\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 94/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.40it/s, loss=0.21] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 94/100\nTrain Loss: 0.6255 | Val Loss: 0.3606\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 95/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.38it/s, loss=0.349]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 95/100\nTrain Loss: 0.6365 | Val Loss: 0.3657\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 96/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.44it/s, loss=0.436]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 96/100\nTrain Loss: 0.6577 | Val Loss: 0.3516\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 97/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.41it/s, loss=0.513]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 97/100\nTrain Loss: 0.6366 | Val Loss: 0.3641\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 98/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.43it/s, loss=0.755]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 98/100\nTrain Loss: 0.6283 | Val Loss: 0.3609\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 99/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.33it/s, loss=0.61] \nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 99/100\nTrain Loss: 0.6576 | Val Loss: 0.3666\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 100/100 [Train]: 100%|██████████| 32/32 [00:01<00:00, 18.30it/s, loss=0.686]\nValidating: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 100/100\nTrain Loss: 0.6380 | Val Loss: 0.4699\nVal Accuracy: 0.8687 | Val F1: 0.8646\n\nMetrics saved to ./synth_output_tuning/training_metrics.xlsx\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"/kaggle/working/synth_output_tuning/best_model.pt\"))\nevaluator = ModelEvaluator(model, clear_test_loader, config_output_general)\ntest_metrics_output_synth_on_clear = evaluator.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:37:51.331447Z","iopub.execute_input":"2025-02-18T17:37:51.331763Z","iopub.status.idle":"2025-02-18T17:37:51.919258Z","shell.execute_reply.started":"2025-02-18T17:37:51.331728Z","shell.execute_reply":"2025-02-18T17:37:51.918575Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-26-ef2d24fa06eb>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"/kaggle/working/synth_output_tuning/best_model.pt\"))\nTesting: 100%|██████████| 7/7 [00:00<00:00, 25.74it/s]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print_test_metrics(test_metrics_output_synth_on_clear)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:37:51.920066Z","iopub.execute_input":"2025-02-18T17:37:51.920363Z","iopub.status.idle":"2025-02-18T17:37:51.925949Z","shell.execute_reply.started":"2025-02-18T17:37:51.920329Z","shell.execute_reply":"2025-02-18T17:37:51.925159Z"}},"outputs":[{"name":"stdout","text":"test_loss: 0.34385326504707336\naccuracy: 0.8686868686868687\nf1_weighted: 0.8646464646464648\nprecision_macro: 0.832867697274477\nrecall_macro: 0.8226498449513614\nclassification_report\n              precision    recall  f1-score   support\n\n     NEUTRAL       0.86      0.57      0.69        21\n    POSITIVE       0.95      0.95      0.95        59\n    NEGATIVE       0.69      0.95      0.80        19\n\n    accuracy                           0.87        99\n   macro avg       0.83      0.82      0.81        99\nweighted avg       0.88      0.87      0.86        99\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"onnx_export = ONNXExporter(model.to(\"cpu\"), tokenizer, config_output_general)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:43:19.919411Z","iopub.execute_input":"2025-02-18T17:43:19.919865Z","iopub.status.idle":"2025-02-18T17:43:19.953693Z","shell.execute_reply.started":"2025-02-18T17:43:19.919837Z","shell.execute_reply":"2025-02-18T17:43:19.952840Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"onnx_export.export()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:43:21.297572Z","iopub.execute_input":"2025-02-18T17:43:21.297907Z","iopub.status.idle":"2025-02-18T17:43:22.027946Z","shell.execute_reply.started":"2025-02-18T17:43:21.297883Z","shell.execute_reply":"2025-02-18T17:43:22.027237Z"}},"outputs":[],"execution_count":34}]}